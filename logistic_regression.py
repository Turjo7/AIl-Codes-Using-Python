# -*- coding: utf-8 -*-
"""011152200_Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y1Cj4P0HcP0DN_R60MHfSeUpjDQN7RzP
"""

from sklearn import datasets
import numpy as np
iris = datasets.load_iris()
x = iris.data[:, :2]
y = (iris.target != 0) * 1

print(x.shape)
print(y.shape)
print(y)

new_x = []

for i in range (len(x)):
  temp = []
  temp.append(1)
  temp.append(x[i][0]) 
  temp.append(x[i][1])
  new_x.append(temp)
print(new_x)

import random 
#random.seed(1)

x_train = []
y_train = []
x_test = []
y_test = []
x_val = []
y_val = []

for S in range(150):
  R = random.uniform(0,1)
  if R >= 0.0 and R <= .70:
    x_train.append(new_x[S])
    y_train.append(y[S])
  elif R > .70 and R <= .85:
    x_val.append(new_x[S])
    y_val.append(y[S])
  else:
    x_test.append(new_x[S])
    y_test.append(y[S])
print(len(x_train))
print(len(x_test))
print(len(x_val))

import math

theta = []

for i in range(3):
  R = random.uniform(0,1)
  theta.append(R)
print(theta)

lr = 0.00001
train_loss = []

for iteration in range(1000):
  tj = 0 
  for i in range(len(x_train)):
    z = np.dot(x_train[i],theta)
    h = 1 / (1 + math.exp(-z))
    j = (-y_train[i] * np.log(h)) - ((1-y_train[i]) * np.log(1-h))
    tj = tj + j
    dv = np.array(x_train[i])*(h-y_train[i])
    theta = theta - (np.array(dv) * lr)
  
  tj = tj/len(x_train)
  print(tj)
  train_loss.append(tj)
  
print(train_loss)
print(theta)